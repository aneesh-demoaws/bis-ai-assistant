<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIS AI Voice Assistant</title>
    <style>
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body { font-family: system-ui, sans-serif; background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); min-height: 100vh; display: flex; flex-direction: column; align-items: center; justify-content: center; color: #fff; }
        .container { text-align: center; padding: 2rem; max-width: 500px; }
        h1 { margin-bottom: 0.5rem; font-size: 1.8rem; }
        .subtitle { color: #888; margin-bottom: 1.5rem; }
        
        /* Avatar */
        .avatar-container { position: relative; width: 120px; height: 120px; margin: 0 auto 1.5rem; }
        .avatar { width: 120px; height: 120px; border-radius: 50%; background: linear-gradient(145deg, #60a5fa, #3b82f6); display: flex; align-items: center; justify-content: center; font-size: 3.5rem; position: relative; z-index: 2; box-shadow: 0 8px 32px rgba(59,130,246,0.4); transition: transform 0.3s; border: 4px solid #fff; }
        .avatar.speaking { animation: avatarPulse 0.5s ease-in-out infinite alternate; }
        @keyframes avatarPulse { from { transform: scale(1); } to { transform: scale(1.05); } }
        
        /* Sound waves */
        .sound-wave { position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); width: 120px; height: 120px; border-radius: 50%; border: 3px solid rgba(59,130,246,0.5); opacity: 0; z-index: 1; }
        .avatar.speaking ~ .sound-wave { animation: soundWave 1.5s ease-out infinite; }
        .sound-wave:nth-child(3) { animation-delay: 0.5s; }
        .sound-wave:nth-child(4) { animation-delay: 1s; }
        @keyframes soundWave { 0% { width: 120px; height: 120px; opacity: 0.6; } 100% { width: 220px; height: 220px; opacity: 0; } }
        
        #micBtn { width: 100px; height: 100px; border-radius: 50%; border: none; background: linear-gradient(145deg, #e94560, #c73e54); color: #fff; font-size: 2.5rem; cursor: pointer; transition: all 0.3s; box-shadow: 0 8px 32px rgba(233,69,96,0.3); }
        #micBtn:hover { transform: scale(1.05); }
        #micBtn.recording { background: linear-gradient(145deg, #4ade80, #22c55e); animation: pulse 1.5s infinite; }
        #micBtn:disabled { background: #444; cursor: not-allowed; }
        @keyframes pulse { 0%, 100% { box-shadow: 0 0 0 0 rgba(74,222,128,0.4); } 50% { box-shadow: 0 0 0 20px rgba(74,222,128,0); } }
        #status { margin-top: 1rem; font-size: 1.1rem; min-height: 1.5rem; }
        #transcript { margin-top: 1.5rem; padding: 1rem; background: rgba(255,255,255,0.1); border-radius: 12px; min-height: 100px; max-height: 250px; overflow-y: auto; text-align: left; }
        .msg { padding: 0.5rem 0; border-bottom: 1px solid rgba(255,255,255,0.1); }
        .msg.user { color: #4ade80; }
        .msg.assistant { color: #60a5fa; }
        .msg.system { color: #fbbf24; font-style: italic; }
        .msg:last-child { border-bottom: none; }
        .preview { opacity: 0.6; }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéì BIS AI Assistant</h1>
        <p class="subtitle">Bhavans Indian School Voice Chat</p>
        
        <div class="avatar-container">
            <div class="avatar" id="avatar">üë®‚Äçüíº</div>
            <div class="sound-wave"></div>
            <div class="sound-wave"></div>
            <div class="sound-wave"></div>
        </div>
        
        <button id="micBtn" onclick="toggleRecording()">üé§</button>
        <div id="status">Click to start talking</div>
        <div id="transcript"></div>
    </div>
    <script>
        const WS_URL = 'wss://bisai-alb.demoaws.com/voice';
        let ws, audioCtx, mediaStream, workletNode, isRecording = false;
        let playbackCtx, nextPlayTime = 0;
        const pendingBuffers = [];
        let isAssistantSpeaking = false;

        function updateAvatar() {
            const avatar = document.getElementById('avatar');
            avatar.classList.toggle('speaking', isAssistantSpeaking);
        }

        async function toggleRecording() {
            if (isRecording) stopRecording();
            else await startRecording();
        }

        async function startRecording() {
            try {
                setStatus('Connecting...');
                ws = new WebSocket(WS_URL);
                
                ws.onopen = async () => {
                    setStatus('üéôÔ∏è Listening... speak anytime');
                    
                    audioCtx = new AudioContext({ sampleRate: 16000 });
                    playbackCtx = new AudioContext({ sampleRate: 16000 });
                    nextPlayTime = playbackCtx.currentTime;
                    
                    mediaStream = await navigator.mediaDevices.getUserMedia({ 
                        audio: { sampleRate: 16000, channelCount: 1, echoCancellation: true, noiseSuppression: true, autoGainControl: true }
                    });
                    
                    const source = audioCtx.createMediaStreamSource(mediaStream);
                    
                    const processor = audioCtx.createScriptProcessor(2048, 1, 1);
                    processor.onaudioprocess = (e) => {
                        if (ws?.readyState === WebSocket.OPEN) {
                            const pcm = e.inputBuffer.getChannelData(0);
                            const int16 = new Int16Array(pcm.length);
                            for (let i = 0; i < pcm.length; i++) {
                                int16[i] = Math.max(-32768, Math.min(32767, pcm[i] * 32768));
                            }
                            const b64 = arrayBufferToBase64(int16.buffer);
                            ws.send(JSON.stringify({ type: 'audio', data: b64 }));
                        }
                    };
                    source.connect(processor);
                    processor.connect(audioCtx.destination);
                    
                    isRecording = true;
                    updateMicButton();
                };
                
                ws.onmessage = (e) => {
                    const msg = JSON.parse(e.data);
                    
                    if (msg.type === 'audio') {
                        scheduleAudio(msg.data);
                        if (!isAssistantSpeaking) {
                            isAssistantSpeaking = true;
                            updateMicButton();
                            updateAvatar();
                            setStatus('üîä Assistant speaking... (interrupt anytime)');
                        }
                    } else if (msg.type === 'transcript') {
                        updateTranscript(msg.role, msg.text, msg.is_final);
                    } else if (msg.type === 'interruption') {
                        clearAudioQueue();
                        isAssistantSpeaking = false;
                        updateMicButton();
                        updateAvatar();
                        setStatus('üéôÔ∏è Listening...');
                        addSystemMessage('‚ö° Interrupted');
                    } else if (msg.type === 'response_end') {
                        isAssistantSpeaking = false;
                        updateMicButton();
                        updateAvatar();
                        setStatus('üéôÔ∏è Listening... speak anytime');
                    } else if (msg.type === 'error') {
                        setStatus('‚ùå ' + msg.message);
                    }
                };
                
                ws.onclose = () => { 
                    stopRecording(); 
                    setStatus('Disconnected - click to reconnect'); 
                };
                ws.onerror = () => { 
                    stopRecording(); 
                    setStatus('Connection error'); 
                };
            } catch (err) { 
                setStatus('Error: ' + err.message); 
            }
        }

        function stopRecording() {
            if (ws?.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({ type: 'stop' }));
                ws.close();
            }
            if (mediaStream) mediaStream.getTracks().forEach(t => t.stop());
            if (audioCtx) audioCtx.close().catch(() => {});
            if (playbackCtx) playbackCtx.close().catch(() => {});
            clearAudioQueue();
            isRecording = false;
            isAssistantSpeaking = false;
            updateMicButton();
            updateAvatar();
            setStatus('Click to start talking');
        }

        function arrayBufferToBase64(buffer) {
            const bytes = new Uint8Array(buffer);
            let binary = '';
            for (let i = 0; i < bytes.length; i++) binary += String.fromCharCode(bytes[i]);
            return btoa(binary);
        }

        function base64ToInt16Array(b64) {
            const binary = atob(b64);
            const bytes = new Uint8Array(binary.length);
            for (let i = 0; i < binary.length; i++) bytes[i] = binary.charCodeAt(i);
            return new Int16Array(bytes.buffer);
        }

        function scheduleAudio(b64) {
            if (!playbackCtx) return;
            
            const int16 = base64ToInt16Array(b64);
            const float32 = new Float32Array(int16.length);
            for (let i = 0; i < int16.length; i++) float32[i] = int16[i] / 32768;
            
            const buffer = playbackCtx.createBuffer(1, float32.length, 16000);
            buffer.copyToChannel(float32, 0);
            
            const source = playbackCtx.createBufferSource();
            source.buffer = buffer;
            source.connect(playbackCtx.destination);
            
            const now = playbackCtx.currentTime;
            if (nextPlayTime < now) nextPlayTime = now;
            
            source.start(nextPlayTime);
            pendingBuffers.push(source);
            nextPlayTime += buffer.duration;
            
            source.onended = () => {
                const idx = pendingBuffers.indexOf(source);
                if (idx > -1) pendingBuffers.splice(idx, 1);
            };
        }

        function clearAudioQueue() {
            pendingBuffers.forEach(src => {
                try { src.stop(); } catch (e) {}
            });
            pendingBuffers.length = 0;
            if (playbackCtx) nextPlayTime = playbackCtx.currentTime;
        }

        let currentPreview = null;
        function updateTranscript(role, text, isFinal) {
            const div = document.getElementById('transcript');
            
            if (!isFinal) {
                if (!currentPreview || currentPreview.dataset.role !== role) {
                    currentPreview = document.createElement('div');
                    currentPreview.className = 'msg ' + role + ' preview';
                    currentPreview.dataset.role = role;
                    div.appendChild(currentPreview);
                }
                currentPreview.textContent = (role === 'user' ? 'üë§ ' : 'ü§ñ ') + text + '...';
            } else {
                if (currentPreview && currentPreview.dataset.role === role) {
                    currentPreview.classList.remove('preview');
                    currentPreview.textContent = (role === 'user' ? 'üë§ ' : 'ü§ñ ') + text;
                    currentPreview = null;
                } else {
                    const p = document.createElement('div');
                    p.className = 'msg ' + role;
                    p.textContent = (role === 'user' ? 'üë§ ' : 'ü§ñ ') + text;
                    div.appendChild(p);
                }
            }
            div.scrollTop = div.scrollHeight;
        }

        function addSystemMessage(text) {
            const div = document.getElementById('transcript');
            const p = document.createElement('div');
            p.className = 'msg system';
            p.textContent = text;
            div.appendChild(p);
            div.scrollTop = div.scrollHeight;
        }

        function updateMicButton() {
            const btn = document.getElementById('micBtn');
            btn.classList.remove('recording');
            if (!isRecording) {
                btn.textContent = 'üé§';
            } else {
                btn.classList.add('recording');
                btn.textContent = 'üéôÔ∏è';
            }
        }

        function setStatus(s) { document.getElementById('status').textContent = s; }
    </script>
</body>
</html>
